{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGAN for testing mediation effects\n",
    "\n",
    "### In the following, we conduct a simulation study to demonstrate the usage of LOGAN. The data generating process is the same as the first simulation scenario in Shi and Li (2020). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.06456235 0.\n",
      " 1.0276047  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.63224855 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.08345408 0.\n",
      " 0.64163798 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.31447262\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import networkx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import LOGAN.utils as ut\n",
    "import matplotlib.cm as cm\n",
    "ut.set_random_seed(12345)\n",
    "p = 50\n",
    "W, _ = ut.generate_dag_exam1(p, prob=[0.05, 0.15])\n",
    "\n",
    "W_star = abs(W).copy()\n",
    "W_tem = W_star.copy()\n",
    "for j in range(p+1):\n",
    "    for i in range(len(W)):\n",
    "        W_star[i, :] = np.amax(np.minimum(np.outer(W_star[i, :], np.ones(len(W))), abs(W)), axis=0)\n",
    "    W_tem = np.maximum(W_tem, W_star)\n",
    "W_star = W_tem.copy()\n",
    "strength = np.array([W_star[i,0]*W_star[p+1,i] for i in np.arange(1, p+1)])\n",
    "print(strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The matrix `W` corresponds to the weight adjacency matrix. The vector `strength` measures the individual mediation effects. Under $H_0(q)$, the `q`th element in `strength` equals zero. Under $H_1(q)$, it is strictly positive. The larger the absolute value, the stronger the mediation effects. The following code allows us to visualize the adjacency matrix `W`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'True adjacency matrix')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('bwr')\n",
    "cmap.set_bad(color='white')\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "img = ax.imshow(W, cmap=cmap, vmin=-2, vmax=2)\n",
    "plt.colorbar(img)\n",
    "plt.title(\"True adjacency matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We next run `M` simulations to investigate the finite sample performance of the proposed test. The following code implements Step 1 and 2 of the proposed test. Specifically,\n",
    "* Step 1: **Data splitting**. Here `L` denotes the number of data splits. If `L=1`, it reduces to the binary-split test detailed in Section 4 of Shi and Li (2020). If `L>1`, it yields a multi-split test detailed in the appendix. \n",
    "* Step 2: **Initial DAG estimation**. We adopt the NOTEARS algorithm to compute `W_est1` and `W_est2`, the estimated adjacency matrices. These matrices will be saved into CSV files. `w` is a thresholding parameter. It is used to ensure the estimated adjacency matrix satisfies the DAG constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "n_sample = 100\n",
    "M = 1\n",
    "L = 3\n",
    "for k in np.arange(1,M+1):\n",
    "    ut.set_random_seed(12345*k)\n",
    "    data = ut.simulate_linear_sem(1, W.transpose(), n_sample)\n",
    "\n",
    "    ## tuning parameter\n",
    "    lambda1 = 0.5*np.sqrt(np.log(p+1)/(n_sample/2))\n",
    "    w = 1e-3\n",
    "    ## sample splitting\n",
    "    import numpy.random as nr\n",
    "    import LOGAN.notears as nt\n",
    "    from numpy import linalg as LA\n",
    "    import scipy.linalg as slin\n",
    "    for l in np.arange(1,L+1):\n",
    "        ut.set_random_seed(1234567*l)\n",
    "        sample1 = nr.choice(n_sample, int(n_sample/2), replace=False)\n",
    "        sample2 = [x for x in range(n_sample) if x not in set(sample1)]\n",
    "        ## form the data subsets and demean\n",
    "        sub_sample1 = data[sample1, 0:-1].copy()\n",
    "        sub_sample2 = data[sample2, 0:-1].copy()\n",
    "        for j in range(p):\n",
    "            sub_sample1[:,j] = sub_sample1[:,j] - np.mean(sub_sample1[:,j])\n",
    "            sub_sample2[:,j] = sub_sample2[:,j] - np.mean(sub_sample2[:,j])\n",
    "        ## apply notears\n",
    "        W_est1 = nt.notears_linear_l1(sub_sample1, lambda1=lambda1, max_iter=500, loss_type='l2', w_threshold=w) \n",
    "        W_est2 = nt.notears_linear_l1(sub_sample2, lambda1=lambda1, max_iter=500, loss_type='l2', w_threshold=w)\n",
    "        np.savetxt('./results/W_est1'+str(l)+str(k)+'.csv', W_est1, delimiter=',')\n",
    "        np.savetxt('./results/W_est2'+str(l)+str(k)+'.csv', W_est2, delimiter=',')\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code implements Step 3 and 4 of the proposed test. Specifically,\n",
    "\n",
    "* Step 3: **Screening and debiasing**. Functions `_refit`, `_ancestor` and `_decor_score` implement this step. `_refit` is applied to the initial DAG estimator to refit the coefficients with penalized MCP regression (Zhang, 2010). `_ancestor` outputs a boolean matrix that specifies the set of ancestors for each node. `_decor_score` returns the debiased estimate.  \n",
    "* Step 4: **Bootstrap for critical values**. Here, we directly compute the p-value associated with each mediator (see Section 4.5 of Shi and Li, 2020). The output `test1` is a $p\\times 2\\times 2L \\times M$ matrix, containing the p-values for all $p$ mediators, over all $M$ simulations and $2L$ data splits. `test1[:,0,:,:]` contains p-values for $H_0(q,d+1)$ whereas `test1[:,1,:,:]` contains p-values for $H_0(0,q)$. The output will be saved into a pickle file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import LOGAN.sparselearn as sl\n",
    "test1 = np.zeros((p,2,2*L,M))\n",
    "pickle.dump(test1, open( \"./results/n100p50.p\", \"wb\" ) )\n",
    "n_sample = 100\n",
    "for k in np.arange(1,M+1):\n",
    "    ut.set_random_seed(12345*k)\n",
    "    data = ut.simulate_linear_sem(1, W.transpose(), n_sample)\n",
    "    for m in np.arange(1,L+1):\n",
    "        ut.set_random_seed(1234567*m)\n",
    "        sample1 = nr.choice(n_sample, int(n_sample/2), replace=False)\n",
    "        sample2 = [x for x in range(n_sample) if x not in set(sample1)]\n",
    "\n",
    "        w = 1e-3\n",
    "        W_est1 = np.loadtxt('./results/W_est1'+str(m)+str(k)+'.csv', delimiter=',')\n",
    "        W_est2 = np.loadtxt('./results/W_est2'+str(m)+str(k)+'.csv', delimiter=',')\n",
    "        W_est1[:,0] = 0\n",
    "        W_est2[:,0] = 0\n",
    "        while True:\n",
    "            M0 = np.eye(p+1) + W_est1 * W_est1 / (p+1)\n",
    "            E = np.linalg.matrix_power(M0, p)\n",
    "            h = (E.T * M0).sum() - (p+1)\n",
    "            if h<=0:\n",
    "                break\n",
    "            else:\n",
    "                w = 2*w \n",
    "                W_est1[np.abs(W_est1)<=w] = 0\n",
    "        while True:\n",
    "            M0 = np.eye(p+1) + W_est2 * W_est2 / (p+1)\n",
    "            E = np.linalg.matrix_power(M0, p)\n",
    "            h = (E.T * M0).sum() - (p+1)\n",
    "            if h<=0:\n",
    "                break\n",
    "            else:\n",
    "                w = 2*w \n",
    "                W_est2[np.abs(W_est2)<=w] = 0\n",
    "\n",
    "        critic1 = np.zeros((1000,))\n",
    "        critic2 = np.zeros((1000,))\n",
    "        W_refit1 = sl._refit(data[sample1,:], int(n_sample/2), p+2, W_est1)\n",
    "        W_refit2 = sl._refit(data[sample2,:], int(n_sample/2), p+2, W_est2)\n",
    "\n",
    "        sub_sample1 = data[sample1, :].copy()\n",
    "        sub_sample2 = data[sample2, :].copy()\n",
    "        for j in range(p+1):\n",
    "            sub_sample1[:,j] = sub_sample1[:,j] - np.mean(sub_sample1[:,j])\n",
    "            sub_sample2[:,j] = sub_sample2[:,j] - np.mean(sub_sample2[:,j])\n",
    "        sigma1 = np.mean(np.square(sub_sample2 - sub_sample2 @ W_refit1.transpose()))\n",
    "        sigma2 = np.mean(np.square(sub_sample1 - sub_sample1 @ W_refit2.transpose()))\n",
    "        sigma = np.sqrt((sigma1+sigma2)/2)\n",
    "\n",
    "        B1 = sl._ancestor(W_est1)\n",
    "        W_ds2, Boot_W2 = sl._decor_score(data[sample2,:], W_refit1, B1)\n",
    "        W_est_star = sl._W_star(W_ds2.copy(), p)\n",
    "        for q in np.arange(1, p+1):\n",
    "            Ind1 = np.full(p+2, True)\n",
    "            Ind2 = np.full(p+2, True)\n",
    "            Ind1[B1[:,q]==False] = False\n",
    "            Ind1[0:-1][B1[p+1,-1]==False] = False\n",
    "            Ind2[B1[:,q]==False] = False\n",
    "            Ind2[q] = True\n",
    "            Ind2[B1[p+1,:]==False] = False\n",
    "            for l in range(1000):\n",
    "                Boot_W = np.copy(Boot_W2[:,:,l])\n",
    "                Boot_W[W_refit1==0] = 0\n",
    "                if (sum(Ind1)==0)|(sum(Ind2)==0):\n",
    "                    critic1[l] = 0\n",
    "                else:\n",
    "                    critic1[l] = np.amax(abs(Boot_W[np.ix_(Ind1,Ind2)]))*sigma\n",
    "            test1[q-1,0,2*(m-1),k-1] = np.mean(critic1>=W_est_star[p+1,q])\n",
    "\n",
    "            Ind1 = np.full(p+2, True)\n",
    "            Ind2 = np.full(p+2, True)\n",
    "            Ind1[B1[q,:]==False] = False\n",
    "            Ind1[q] = True\n",
    "            Ind1[B1[:,0]==False] = False\n",
    "            Ind2[B1[:,0]==False] = False\n",
    "            Ind2[0] = True\n",
    "            Ind2[B1[q,:]==False] = False\n",
    "            for l in range(1000):\n",
    "                Boot_W = np.copy(Boot_W2[:,:,l])\n",
    "                Boot_W[W_refit1==0] = 0\n",
    "                if (sum(Ind1)==0)|(sum(Ind2)==0):\n",
    "                    critic1[l] = 0\n",
    "                else:\n",
    "                    critic1[l] = np.amax(abs(Boot_W[np.ix_(Ind1,Ind2)]))*sigma  \n",
    "            test1[q-1,1,2*(m-1),k-1] = np.mean(critic1>=W_est_star[q,0])\n",
    "\n",
    "        B2 = sl._ancestor(W_est2)\n",
    "        W_ds1, Boot_W1 = sl._decor_score(data[sample1,:], W_refit2, B2)\n",
    "        W_est_star = sl._W_star(W_ds1.copy(), p)\n",
    "        for q in np.arange(1, p+1):\n",
    "            Ind1 = np.full(p+2, True)\n",
    "            Ind2 = np.full(p+2, True)\n",
    "            Ind1[B2[:,q]==False] = False\n",
    "            Ind1[0:-1][B2[p+1,-1]==False] = False\n",
    "            Ind2[B2[:,q]==False] = False\n",
    "            Ind2[q] = True\n",
    "            Ind2[B2[p+1,:]==False] = False\n",
    "            for l in range(1000):\n",
    "                Boot_W = np.copy(Boot_W1[:,:,l])\n",
    "                Boot_W[W_refit2==0] = 0\n",
    "                if (sum(Ind1)==0)|(sum(Ind2)==0):\n",
    "                    critic2[l] = 0\n",
    "                else:\n",
    "                    critic2[l] = np.amax(abs(Boot_W[np.ix_(Ind1,Ind2)]))*sigma\n",
    "            test1[q-1,0,2*m-1,k-1] = np.mean(critic2>=W_est_star[p+1,q])\n",
    "\n",
    "            Ind1 = np.full(p+2, True)\n",
    "            Ind2 = np.full(p+2, True)\n",
    "            Ind1[B2[q,:]==False] = False\n",
    "            Ind1[q] = True\n",
    "            Ind1[B2[:,0]==False] = False\n",
    "            Ind2[B2[:,0]==False] = False\n",
    "            Ind2[0] = True\n",
    "            Ind2[B2[q,:]==False] = False\n",
    "            for l in range(1000):\n",
    "                Boot_W = np.copy(Boot_W1[:,:,l])\n",
    "                Boot_W[W_refit2==0] = 0\n",
    "                if (sum(Ind1)==0)|(sum(Ind2)==0):\n",
    "                    critic2[l] = 0\n",
    "                else:\n",
    "                    critic2[l] = np.amax(abs(Boot_W[np.ix_(Ind1,Ind2)]))*sigma\n",
    "            test1[q-1,1,2*m-1,k-1] = np.mean(critic2>=W_est_star[q,0])\n",
    "    \n",
    "    pickle.dump(test1, open( \"./results/n100p50.p\", \"wb\" ) )\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the test of Chakrabortty et al. (2018), MIDA. The following code implements the MIDA test over `M` simulations. The p-values are given by `pv` at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "Training is over.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy.matlib\n",
    "Est = np.zeros((p,M))\n",
    "Std = np.zeros((p,M))\n",
    "for k in np.arange(1,M+1):\n",
    "    ut.set_random_seed(12345*k)\n",
    "    data = ut.simulate_linear_sem(1, W.transpose(), n_sample)\n",
    "\n",
    "    ## tuning parameter\n",
    "    lambda1 = 0.5*np.sqrt(np.log(p+1)/(n_sample))\n",
    "    w = 1e-3\n",
    "    ## sample splitting\n",
    "    import numpy.random as nr\n",
    "    import LOGAN.notears as nt\n",
    "    from numpy import linalg as LA\n",
    "    import scipy.linalg as slin\n",
    "    ## form the data subsets and demean\n",
    "    sample = data[:, 0:-1].copy()\n",
    "    for j in range(p):\n",
    "        sample[:,j] = sample[:,j] - np.mean(sample[:,j])\n",
    "    ## apply notears\n",
    "    W_est = nt.notears_linear_l1(sample, lambda1=lambda1, max_iter=500, loss_type='l2', w_threshold=w) \n",
    "    \n",
    "    W_est[:,0] = 0\n",
    "    while True:\n",
    "        M0 = np.eye(p+1) + W_est * W_est / (p+1)\n",
    "        E = np.linalg.matrix_power(M0, p)\n",
    "        h = (E.T * M0).sum() - (p+1)\n",
    "        if h<=0:\n",
    "            break\n",
    "        else:\n",
    "            w = 2*w \n",
    "            W_est[np.abs(W_est)<=w] = 0\n",
    "\n",
    "    W_refit = sl._refit(data, n_sample, p+2, W_est)\n",
    "    sample = data.copy()\n",
    "    for j in range(p+1):\n",
    "        sample[:,j] = sample[:,j] - np.mean(sample[:,j])\n",
    "    sigma = np.sqrt(np.mean(np.square(sample - sample @ W_refit.transpose())))\n",
    "\n",
    "    for j in np.arange(1,p+1):\n",
    "        lsfit1 = np.linalg.lstsq(np.vstack([np.ones(n_sample), data[:,0]]).transpose(), data[:,j], rcond=None)\n",
    "        Index = np.full(p+2, False)\n",
    "        Index[W_refit[j,:]!=0] = True\n",
    "        Index[0] = True\n",
    "        Index[j] = True\n",
    "        lsfit2 = np.linalg.lstsq(np.vstack([np.ones(n_sample), data[:,Index].transpose()]).transpose(), data[:,-1], rcond=None)\n",
    "\n",
    "        Est[j-1,k-1] = lsfit1[0][1]*lsfit2[0][sum(Index)]\n",
    "        mat1 = np.vstack([np.ones(n_sample), data[:,0]]).transpose()\n",
    "        mat2 = np.vstack([np.ones(n_sample), data[:,Index].transpose()]).transpose()\n",
    "        res1 = data[:,j]-np.dot(mat1, lsfit1[0])\n",
    "        res2 = data[:,-1]-np.dot(mat2, lsfit2[0])\n",
    "        matres1 = np.multiply(np.matlib.repmat(res1, 2, 1).transpose(), mat1)\n",
    "        matres2 = np.multiply(np.matlib.repmat(res2, sum(Index)+1, 1).transpose(), mat2)\n",
    "        matmat1 = np.dot(mat1.transpose(), mat1)\n",
    "        matmat2 = np.dot(mat2.transpose(), mat2)\n",
    "        vec = lsfit2[0][sum(Index)]*np.linalg.solve(matmat1, matres1.transpose())[1,:]\n",
    "        vec = vec + lsfit1[0][1]*np.linalg.solve(matmat2, matres2.transpose())[sum(Index),:]\n",
    "        Std[j-1,k-1] = np.linalg.norm(vec, 2)*sigma\n",
    "    \n",
    "    print(k)\n",
    "\n",
    "from scipy.stats import norm\n",
    "pv = 2*(1-norm.cdf(abs(Est)[:,np.sum(abs(Est),0)>0]/Std[:,np.sum(abs(Est),0)>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code compares the two tests using the ROC curve. The individual p-values of the proposed test are given by `pvalue1` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-3d4510709ff9>:17: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  tpr = interp(base_fpr, fpr, tpr)\n",
      "<ipython-input-6-3d4510709ff9>:31: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  tpr = interp(base_fpr, fpr, tpr)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11c78de50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test1 = pickle.load( open( \"./results/n100p50.p\", \"rb\" ) )\n",
    "pvalue1 = np.zeros((p,2,M))\n",
    "for k in np.arange(0,M):\n",
    "    for l in range(2):\n",
    "        gamma = 0.1\n",
    "        pvalue1[:,l,k] = np.quantile(test1[:,l,:,k]/gamma, gamma, axis=1)\n",
    "pvalue1 = np.maximum(pvalue1[:,0,:], pvalue1[:,1,:])\n",
    "pvalue1[pvalue1>1] = 1\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve\n",
    "tprs = []\n",
    "base_fpr = np.linspace(0, 1, 1001)\n",
    "for i in np.arange(0,M):\n",
    "    fpr, tpr, _ = roc_curve(strength==0, pv[:,i], pos_label=1)\n",
    "    tpr = interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tprs.append(tpr)\n",
    "    \n",
    "tprs = np.array(tprs)\n",
    "mean_tprs = tprs.mean(axis=0)\n",
    "std = tprs.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "tprs_lower = mean_tprs - std\n",
    "\n",
    "tprs1 = []\n",
    "for i in np.arange(0,M):\n",
    "    fpr, tpr, _ = roc_curve(strength==0, pvalue1[:,i], pos_label=1)\n",
    "    tpr = interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tprs1.append(tpr)\n",
    "    \n",
    "tprs1 = np.array(tprs1)\n",
    "mean_tprs1 = tprs1.mean(axis=0)\n",
    "std1 = tprs1.std(axis=0)\n",
    "\n",
    "tprs1_upper = np.minimum(mean_tprs1 + std1, 1)\n",
    "tprs1_lower = mean_tprs1 - std1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(6,6))\n",
    "ax.plot(base_fpr, mean_tprs, 'bs-', label='MIDA')\n",
    "ax.plot(base_fpr, mean_tprs1, 'ro-', label='LOGAN')\n",
    "ax.plot([0, 1], [0, 1],'g--')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code implements the proposed multiple testing procedure, based on the proposed test, the ScreenMin (Djordjilovic et al., 2019) and the Benjamini-Yekutieli (BY, Benjamini and Yekutieli, 2001) procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pickle.load( open( \"./results/n100p50.p\", \"rb\" ) )\n",
    "base_q = np.linspace(0, 0.4, 21)\n",
    "len_base = len(base_q)\n",
    "pvalue0 = np.zeros((p, M, len_base, 2))\n",
    "fdr = np.zeros((M, len_base))\n",
    "tpr = np.zeros((M, len_base))\n",
    "test = np.zeros((p, M, len_base))\n",
    "for m in range(len_base):\n",
    "    threshold0 = base_q[m]/np.arange(1,p+1)\n",
    "    for k in range(M):\n",
    "        for l in range(2):\n",
    "            for j in np.arange(1,p+1):\n",
    "                set0 = np.minimum(test1[:,0,l,k], test1[:,1,l,k])<=threshold0[j-1]\n",
    "                if threshold0[j-1]*sum(set0) <= base_q[m]:\n",
    "                    break\n",
    "            pvalue0[:,k,m,l] = np.maximum(test1[:,0,l,k], test1[:,1,l,k])\n",
    "            pvalue0[~set0,k,m,l] = 1\n",
    "    for k in range(M):\n",
    "        for l in range(2):\n",
    "            set0 = pvalue0[:,k,m,l]<1\n",
    "            h = (pvalue0[set0,k,m,l][np.argsort(pvalue0[set0,k,m,l])])<=np.arange(1,1+sum(set0))*base_q[m]/(2*sum(set0)*(0.5+np.log(max(1,sum(set0)))))\n",
    "            if sum(h)>0:\n",
    "                test2 = np.zeros(sum(set0))\n",
    "                test2[np.argsort(pvalue0[set0,k,m,l])[0:sum(h)]] = 1\n",
    "                test[set0,k,m] = test2\n",
    "    for k in range(M):\n",
    "        fdr[k,m] = sum(test[strength==0,k,m])/(p-sum(strength!=0))\n",
    "        tpr[k,m] = sum(test[strength!=0,k,m])/sum(strength!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11c7efd30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,3))\n",
    "ax.plot(base_q, np.mean(fdr, axis=0), 'bs-', label='LOGAN-FDR')\n",
    "ax.plot(base_q, np.mean(tpr, axis=0), 'ro-', label='LOGAN-TPR')\n",
    "ax.set_ylim([-0.01,1.01])\n",
    "ax.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
